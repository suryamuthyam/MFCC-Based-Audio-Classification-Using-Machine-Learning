# MFCC-Based-Audio-Classification-Using-Machine-Learning

The idea behind creating this proposed solution was
to build a machine learning model that might detect emotions
from the speech weâ€™ve got with one another all the time. The
prime objective of this solution is to acknowledge emotions in
speech and classify them into 8 emotion output classes namely
neutral, calm, happy, sad, angry, fearful, disgust, and surprised.
The proposed approach relies upon the Mel Frequency Cepstral
coefficients (MFCC) and energy of the speech signals as feature
inputs and uses a RAVDESS database of emotional speech. After
extracting the feature from speech, Those are turned into feature
vectors, which successively want to train different classification
algorithms. Those algorithms are Decision tree, Random Forest,
and Support Vector Machine(SVM). Firstly we are going to
collect the datasets and so by using the MFCC we are going to
do feature extraction, then we are going to load the datasets and
test and train them to 3 machine learning algorithms. .Finally,
we are having the highest accuracy of 88.54 in the random forest
algorithm and got 79.17 while using the SVM algorithm and we
got 71.88 using the Decision Tree.
